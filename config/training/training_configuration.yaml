# ---------- Data configuration ----------
num_classes: 37 # Food 101 / Pets 37
img_size: 224
num_channels: 300

# --- Training operative configuration ---
device: "cuda:0" # Cuda device, i.e. 0 or 0,1,2,3 or cpu
workers: 0 # Maximum number of dataloader workers
batch_size: 30
# Total batch size for all GPUs
# nominal_batch_size: 20 # ONLY IF ACCUMULATE TRUE

epochs: 30 # Number of training epochs

optimizer: "Adam" # [SGD ,Adam ,AdamW, SparseAdam]
criterion: "CrossEntropyLoss" # [NLLLoss, CrossEntropyLoss]
inference: "Softmax" # [Softmax, Sigmoid]
linear_lr: False # linear learning rate (decay)

# Flags
half_precision: True
# warmup: False
# accumulate: False

resume: False # Resume most recent training. True = latest, can be string to a specific checkpoint
nosave: False # Only save final checkpoint
notest: False # Only test final epoch
test_on_train: True # Test metrics on train data
logger: "INFO"

# --- Configuration files and paths ---
architecture_config: "default"
weights: "" # Initial weights path
hyperparameters: "config/training/hypeparameter_configuration.yaml"  # Hyperparameters path
project: "dumps/train" # save to project/name
# TODO: automatize
name: "cnn_heatmap_train" # save to project/name
exist_ok: False # existing project/name ok, do not increment

# TODO: ---
# label_smoothing: 0.0 # Label smoothing epsilon
# cache_images: False # Cache images for faster training
# image_weights: False # Use weighted image selection for training
# quad: False # [experimental] may allow some benefits of higher --img size training at lower --img sizes.
# --- Special training parameters ---
#evolve: True # Evolve hyperparameters
#evolve_epochs: 300 # Epochs of evolution